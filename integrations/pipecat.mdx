Integrate Moss Semantic Search directly into a Pipecat pipeline using the `pipecat-moss` package. This setup allows your voice AI to perform search with sub-10ms latency, ensuring your agents answer questions naturally without awkward "thinking" pauses.

> **Note:** To go through an end-to-end example deployment of `pipecat-moss`, please visit [Moss Samples](https://github.com/usemoss/moss-samples).

## Why Use Moss with Pipecat?

Moss retrieval operates with exceptional speed, seamlessly injecting results into the LLM context before the user completes their turn. This eliminates reliance on slow "tool calling" loops, ensuring interactions remain natural and fluid.

## Required Tools

To integrate Moss with Pipecat, you will need the following tools:

- [Moss](https://www.usemoss.dev/)
- [Pipecat](https://docs.pipecat.ai/getting-started/introduction)

---

## Integration Guide

<Steps>
  <Step title="Installation">
    Install the official Pipecat-Moss integration package.

    ```bash
    pip install pipecat-moss
    ```
  </Step>

  <Step title="Add Moss to Pipeline">
    The `MossRetrievalService` integrates as a **processor** in the Pipecat pipeline. It sits between the user input and the LLM, injecting relevant context automatically.

    ```python
    from pipecat_moss import MossRetrievalService

    moss_service = MossRetrievalService(
        project_id=os.getenv("MOSS_PROJECT_ID"),
        project_key=os.getenv("MOSS_PROJECT_KEY"),
        system_prompt="Relevant passages from the Moss knowledge base:\n\n",
    )

    # Load the Moss index
    await moss_service.load_index(os.getenv("MOSS_INDEX_NAME"))

    # Add Moss to the pipeline
    pipeline = Pipeline([
        transport.input(),
        moss_service.query(os.getenv("MOSS_INDEX_NAME"), top_k=5),
        llm,
        transport.output(),
    ])
    ```
  </Step>
</Steps>

## Configuration

The `MossRetrievalService` allows you to tune how results are retrieved and presented to the LLM.

### Initialization

| Parameter | Type | Description |
| :--- | :--- | :--- |
| `project_id` | `str` | **Required**. Your Moss Project ID. |
| `project_key` | `str` | **Required**. Your Moss Project Key. |
| `system_prompt` | `str` | Prefix text added to the retrieved context. Default: `"Here is additional context retrieved from database:\n\n"`. |

### Pipeline Processor

When adding `moss_service.query()` to your pipeline, you can adjust the following:

| Parameter | Type | Default | Description |
| :--- | :--- | :--- | :--- |
| `top_k` | `int` | `5` | The number of text chunks to retrieve and inject. |
| `alpha` | `float` | `0.8` | **Hybrid Search Weighting**. <br/>`0.0` = Keyword only. <br/>`1.0` = Semantic only (Vector). <br/>`0.8` is recommended for most voice use cases. |